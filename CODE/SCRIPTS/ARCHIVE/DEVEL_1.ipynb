{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8cd37fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#==================================================================\n",
    "#Program: DEVEL_1\n",
    "#Version: 1.0\n",
    "#Author: David Helminiak\n",
    "#Date Created: August 30, 2024\n",
    "#Date Last Modified: September 3, 2024\n",
    "#Description: Re-implementation of a unified block classifier code for breast cancer data\n",
    "#Operation: Move back into main program directory before running.\n",
    "#Status: Deprecated - Need to start adding WSI/block prediction code; moved to DEVEL_2\n",
    "#==================================================================\n",
    "\n",
    "#Have the notebook fill more of the display width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:80% !important; }</style>\"))\n",
    "\n",
    "#Items otherwise covered when not running this code in a notebook\n",
    "import tempfile\n",
    "dir_tmp = tempfile.TemporaryDirectory(prefix='TMP_').name\n",
    "configFileName = './CONFIG_0-TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3054df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================\n",
    "#CONFIG PARAMETERS\n",
    "#==================================================================\n",
    "\n",
    "#TASKS\n",
    "#==================================================================\n",
    "#Should classification of blocks and their originating WSI be performed\n",
    "classifierBlocks = False\n",
    "\n",
    "#Should classifier model components be saved/exported\n",
    "classifierExport = False\n",
    "\n",
    "#Should WSI be segmented into blocks and classified; generates data needed for RANDS\n",
    "classifierWSI = True\n",
    "#==================================================================\n",
    "\n",
    "#CLASSIFICATION - BLOCKS\n",
    "#==================================================================\n",
    "#Should features be extracted for blocks and overwrite previously generated files\n",
    "overwriteBlocks_features = True\n",
    "\n",
    "#Should saliency maps be determined for blocks and overwrite previously generated files\n",
    "overwriteBlocks_saliencyMaps = True\n",
    "\n",
    "#Should the decision fusion mode be used for block classification (default: True)\n",
    "fusionModeBlocks = True\n",
    "\n",
    "#Should saliency maps and their overlays be visualized for blocks (default: False)\n",
    "visualizeBlocks_saliencyMaps = True\n",
    "\n",
    "#How many samples should be submitted in a batch through pytorch models used in classifier; only used for inferencing (default: 1)\n",
    "#Incrementing in powers of 2 recommended to best leverage common GPU hardware designs\n",
    "#For ResNet and DenseNet a 2080TI 11GB reliably handles 64x3x224x224 (resizeBlockSize=[224,224]) or 16x3x400x400 (resizeBlockSize)\n",
    "batchsizeClassifier = 64\n",
    "\n",
    "#Specify what symmetrical dimension images should be resized to; if no resizing is desired leave as 0 (default: 224)\n",
    "#Leaving as [] will increase training time (also must change batchsizeClassifier), but can lead to improved scores\n",
    "#Original implementation uses 224, though with adaptive average pooling this isn't actually neccessary\n",
    "resizeBlockSize = 224\n",
    "\n",
    "#If folds for XGB classifier cross validation should be manually defined (e.g. [['S1', 'S3'], ['S4', 'S2']]), else use specify number of folds to generate\n",
    "#Default matches folds used in prior work (https://doi.org/10.3389/fonc.2023.1179025)\n",
    "#Omits 6 available samples, with folds holding: 11, 12, 12, 12, 13 samples respectively; this may have been to better balance class distribution\n",
    "#Presently, all available (non-excluded) samples (not just those in manualFolds) are currently used for training the exported/utilized final classifier\n",
    "manualFolds = [['2', '9', '11', '16', '34', '36', '40', '54', '57', '60', '62'],\n",
    "               ['17', '20', '23', '24', '28', '30', '33', '51', '52', '59', '63', '66'], \n",
    "               ['12', '14', '22', '26', '35', '44', '45', '47', '49', '53', '56', '68'], \n",
    "               ['4', '5', '8', '10', '25', '27', '29', '37', '42', '48', '50', '69'], \n",
    "               ['7', '15', '19', '31', '43', '46', '55', '58', '61', '64', '65', '67', '70']]\n",
    "\n",
    "#Which pre-trained weight sets should be used for ResNet and DenseNet model: 'IMAGENET1K_V1', 'IMAGENET1K_V2'\n",
    "#Unclear which weights were used for TensorFlow ResNet50 variant in original implementation, but V2 improves the score a bit when using resizeBlockSize = 0\n",
    "weightsResNet = 'IMAGENET1K_V2'\n",
    "\n",
    "#Which pre-trained weight sets should be used for DenseNet model: 'IMAGENET1K_V1'\n",
    "weightsDenseNet = 'IMAGENET1K_V1'\n",
    "\n",
    "#What ratio of malignant to benign blocks should be used to label a whole WSI as malignant\n",
    "#Unknown what the original work used for this value, but chose a value (in range of 0.12-0.19) that can replicate results from original work\n",
    "thresholdWSI = 0.15\n",
    "#==================================================================\n",
    "\n",
    "\n",
    "#CLASSIFICATION - WSI\n",
    "#==================================================================\n",
    "#Should WSI preparation and block extraction overwrite previously generated files\n",
    "overwriteWSI_blocks = True\n",
    "\n",
    "#Should features be extracted for WSI extracted blocks and overwrite previously generated files\n",
    "overwriteWSI_features = True\n",
    "\n",
    "#Should saliency maps be determined for WSI extracted blocks and overwrite previously generated files\n",
    "overwriteWSI_saliencyMaps = True\n",
    "\n",
    "#Should the decision fusion mode be used for block classification (default: True)\n",
    "fusionModeWSI = True\n",
    "\n",
    "#Should saliency maps and their overlays be visualized for WSI extracted blocks (default: False)\n",
    "visualizeWSI_saliencyMaps = True\n",
    "\n",
    "#When splitting WSI images, what size should the resulting blocks be (default: 400)\n",
    "#This should not be changed\n",
    "blockSize = 400\n",
    "\n",
    "#When visualizing a global saliency map, what is the maximum dimension allowable (default: 224)\n",
    "maxDimGlobalSaliencyMap = 224\n",
    "\n",
    "#==================================================================\n",
    "\n",
    "\n",
    "#RARELY CHANGED\n",
    "#==================================================================\n",
    "\n",
    "#What weight should be used when overlaying saliency maps onto other data\n",
    "overlayWeight = 0.5\n",
    "\n",
    "#Should saliency map overlays be placed over data converted to grayscale\n",
    "overlayGray = True\n",
    "\n",
    "#Should the global saliency mask be resized back up to processed WSI dimensions before export (default: False)\n",
    "#Not recommended; generates large images that are generally superfluous\n",
    "globalSaliencyMaskResizeExport = False\n",
    "\n",
    "#Define labels used for normal/benign tissue\n",
    "#'a': normal adipose.\n",
    "#'s': normal stroma tissue excluding adipose.\n",
    "#'o': other normal tissue including parenchyma, adenosis, lobules, blood vessels, etc.\n",
    "benignLabels = ['a', 's', 'o', \n",
    "                'normal', \n",
    "                'fibroadenoma', \n",
    "                'normal breast tissue'\n",
    "               ]\n",
    "\n",
    "#Define labels used for malignant tissue\n",
    "#'d': IDC tumor\n",
    "#'l': ILC tumor\n",
    "#'ot': other tumor areas including DCIS, biopsy site, and slightly defocused tumor regions.\n",
    "malignantLabels = ['d', 'l', 'ot', \n",
    "                   'breast cancer', \n",
    "                   'IMC: Invasive Mucinous', \n",
    "                   'IDC', \n",
    "                   'IMC: IDC with lobular features', \n",
    "                   'IMC: ILC', \n",
    "                   'ILC', \n",
    "                   'Invasive lobular carcinoma'\n",
    "                  ]\n",
    "\n",
    "#Define labels used for tissues to be excluded\n",
    "#'ft': defocused but still visually tumor-like areas.\n",
    "#'f': severly out-of-focusing areas. \n",
    "#'b': background. \n",
    "#'e': bubbles.\n",
    "#Other labels used that were excluded from original work, so doing so here as well\n",
    "excludeLabels = ['ft', 'f', 'b', 'e',\n",
    "                'lymph node',\n",
    "                 'tongue tumor: invasive squamous cell carcinoma', \n",
    "                 'High grade carcinoma in lymph node', \n",
    "                 'osteosarcoma from mandible',\n",
    "                 'normal tongue'\n",
    "                ]\n",
    "#==================================================================\n",
    "\n",
    "\n",
    "\n",
    "#Already in setup CONFIG (avoid duplication during copy)\n",
    "#==================================================================\n",
    "#Should parallelization calls be used to leverage multithreading where able\n",
    "parallelization = True\n",
    "\n",
    "#If parallelization is enabled, how many CPU threads should be used in Ray tasks? (0 will use any/all available)\n",
    "#Recommend starting at half of the available system threads if using hyperthreading,\n",
    "#or 1-2 less than the number of system CPU cores if not using hyperthreading.\n",
    "#Adjust to where the CPU just below 100% usage during parallel operations \n",
    "availableThreads = 16\n",
    "\n",
    "#Which GPU(s) devices should be used (last specified used for data processing and model training); (default: [-1], any/all available; CPU only: [])\n",
    "gpus = [-1]\n",
    "\n",
    "#Should training/validation data be entirely stored on GPU (default: True; improves training/validation efficiency, set to False if OOM occurs)\n",
    "storeOnDevice = True\n",
    "   \n",
    "#RNG seed value to ensure run-to-run consistency (-1 to disable)\n",
    "manualSeedValue = 0\n",
    "\n",
    "debugMode = False\n",
    "\n",
    "asciiFlag = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7c22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================\n",
    "#MAIN - Run codes that have already been completed\n",
    "#==================================================================\n",
    "\n",
    "exec(open(\"./CODE/EXTERNAL.py\", encoding='utf-8').read())\n",
    "\n",
    "exec(open(\"./CODE/COMPUTE.py\", encoding='utf-8').read())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2217c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================\n",
    "#MODEL_CLASS\n",
    "#==================================================================\n",
    "\n",
    "#Load and preprocess data image files\n",
    "#ToTensor() swaps axes (so not used); convert to contiguous torch tensor manually\n",
    "#Rescaling and changing data type only after resizing (otherwise can escape [0, 1])\n",
    "class DataPreprocessing_Classifier(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        super().__init__()\n",
    "        self.filenames = filenames\n",
    "        self.numFiles = len(self.filenames)\n",
    "        self.transform = generateTransform([resizeBlockSize, resizeBlockSize], True, True)\n",
    "        \n",
    "    #Rearranging import dimensions, allows resize transform before tensor-conversion/rescaling; preserves precision and output data range\n",
    "    def __getitem__(self, index): return self.transform(np.moveaxis(cv2.cvtColor(cv2.imread(self.filenames[index], cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB), -1, 0))\n",
    "    \n",
    "    def __len__(self): return self.numFiles\n",
    "\n",
    "#Load/synchronize data labeling, drop excluded rows, and extract relevant metadata\n",
    "def loadMetadata(filename):\n",
    "    metadata = pd.read_excel(filename, header=None, names=['name', 'label'], converters={'name':str,'label':str})\n",
    "    metadata['label'].replace(benignLabels, benignLabel, inplace=True)\n",
    "    metadata['label'].replace(malignantLabels, malignantLabel, inplace=True)\n",
    "    metadata['label'].replace(excludeLabels, excludeLabel, inplace=True)\n",
    "    metadata = metadata.loc[metadata['label'] != excludeLabel]\n",
    "    return np.array(metadata['name']), np.array(metadata['label'])\n",
    "\n",
    "#Compute metrics for a classification result and visualize/save them as needed\n",
    "def computeClassificationMetrics(labels, predictions, baseFilename):\n",
    "    \n",
    "    #Specify data class labels\n",
    "    displayLabels = ['Benign', 'Malignant']\n",
    "    \n",
    "    #Generate/store a classification report: precision, recall, f1-score, and support\n",
    "    classificationReport = classification_report(labels, predictions, target_names=displayLabels, output_dict=True)\n",
    "    classificationReport = pd.DataFrame(classificationReport).transpose()\n",
    "    classificationReport.to_csv(baseFilename + '_classificationReport.csv')\n",
    "\n",
    "    #Generate a confusion matrix and extract relevant statistics\n",
    "    confusionMatrix = confusion_matrix(labels, predictions)\n",
    "    tn, fp, fn, tp = confusionMatrix.ravel()\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    \n",
    "    #Store relevant statistics\n",
    "    summaryReport = {'Accuracy': accuracy, 'Sensitivity': sensitivity, 'Specificity': specificity}\n",
    "    summaryReport = pd.DataFrame.from_dict(summaryReport, orient='index')\n",
    "    summaryReport.to_csv(baseFilename + '_summaryReport.csv')\n",
    "    \n",
    "    #Store confusion matrix\n",
    "    displayCM = ConfusionMatrixDisplay(confusionMatrix, display_labels=displayLabels)\n",
    "    displayCM.plot(cmap='Blues')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(baseFilename+'_confusionMatrix.tif')\n",
    "    plt.close()\n",
    "    \n",
    "#Generate a torch transform needed for preprocessing image data\n",
    "def generateTransform(resizeDims=[], rescale=False, normalize=False,):\n",
    "    transform = [lambda inputs : torch.from_numpy(inputs).contiguous()]\n",
    "    if len(resizeDims) > 0: transform.append(v2.Resize(tuple(resizeDims)))\n",
    "    if rescale: transform.append(lambda inputs: inputs.to(dtype=torch.get_default_dtype()).div(255))\n",
    "    if normalize: transform.append(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
    "    return transforms.Compose(transform)\n",
    "\n",
    "#Export lossless RGB image data to disk\n",
    "def exportImage(filename, image):\n",
    "    writeSuccess = cv2.imwrite(filename, cv2.cvtColor(image, cv2.COLOR_RGB2BGR), params=(cv2.IMWRITE_TIFF_COMPRESSION, 1))\n",
    "    if not writeSuccess: sys.exit('\\nError - Unable to write file: ', filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4333a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================\n",
    "#INTERNAL_DIRECTORY\n",
    "#==================================================================\n",
    "\n",
    "#Indicate and setup the destination folder for results of this configuration\n",
    "destResultsFolder = './RESULTS_'+os.path.splitext(os.path.basename(configFileName).split('_')[1])[0]\n",
    "\n",
    "#If the folder already exists, either remove it, or append a novel value to it\n",
    "if os.path.exists(destResultsFolder):\n",
    "    if not preventResultsOverwrite: \n",
    "        shutil.rmtree(destResultsFolder)\n",
    "    else: \n",
    "        destinationNameValue = 0\n",
    "        destResultsFolder_Base = copy.deepcopy(destResultsFolder)\n",
    "        while True:\n",
    "            destResultsFolder = destResultsFolder_Base + '_' + str(destinationNameValue)\n",
    "            if not os.path.exists(destResultsFolder): break\n",
    "            destinationNameValue += 1\n",
    "\n",
    "#Data input directories and file locations\n",
    "#=============================================================================\n",
    "#Global\n",
    "dir_data = '.' + os.path.sep + 'DATA' + os.path.sep\n",
    "dir_results = '.' + os.path.sep + 'RESULTS' + os.path.sep\n",
    "dir_results_models = dir_results + 'MODELS' + os.path.sep\n",
    "\n",
    "#Block classification\n",
    "dir_blocks_data = dir_data + 'BLOCKS' + os.path.sep\n",
    "dir_blocks_inputs = dir_blocks_data + 'INPUTS' + os.path.sep\n",
    "file_blocks_labels = dir_blocks_inputs + 'Patch_list.xlsx'\n",
    "dir_blocks_features = dir_blocks_data + 'OUTPUT_FEATURES' + os.path.sep\n",
    "dir_blocks_salicencyMaps = dir_blocks_data + 'OUTPUT_SALIENCY_MAPS' + os.path.sep\n",
    "dir_blocks_results = dir_results + 'BLOCKS' + os.path.sep\n",
    "\n",
    "#WSI classification and RANDS data\n",
    "dir_WSI_data = dir_data + 'WSI' + os.path.sep\n",
    "dir_WSI_inputs = dir_WSI_data + 'INPUTS' + os.path.sep\n",
    "file_WSI_labels = dir_WSI_inputs + 'WSI_list.xlsx'\n",
    "dir_WSI_prepared = dir_WSI_data + 'OUTPUT_PREPARED_WSI' + os.path.sep\n",
    "dir_WSI_blocks = dir_WSI_data + 'OUTPUT_BLOCKS' + os.path.sep\n",
    "dir_WSI_features = dir_WSI_data + 'OUTPUT_FEATURES' + os.path.sep\n",
    "dir_WSI_saliencyMaps = dir_WSI_data + 'OUTPUT_SALIENCY_MAPS' + os.path.sep\n",
    "dir_WSI_assembled = dir_WSI_data + 'OUTPUT_ASSEMBLED' + os.path.sep\n",
    "dir_WSI_assembled_saliencyMaps = dir_WSI_assembled + 'SALIENCY_MAPS' + os.path.sep\n",
    "dir_WSI_assembled_overlaid = dir_WSI_assembled + 'OVERLAID' + os.path.sep\n",
    "dir_WSI_global = dir_WSI_data + 'OUTPUT_GLOBAL' + os.path.sep\n",
    "dir_WSI_global_saliencyMaps = dir_WSI_global + 'SALIENCY_MAPS' + os.path.sep\n",
    "dir_WSI_global_overlaid = dir_WSI_global + 'OVERLAID' + os.path.sep\n",
    "dir_WSI_results = dir_results + 'WSI' + os.path.sep\n",
    "dir_WSI_predictionMaps = dir_WSI_results + 'PREDICTION_MAPS' + os.path.sep\n",
    "#=============================================================================\n",
    "\n",
    "\n",
    "#If folders do not exist, but their use is enabled, exit the program\n",
    "#=============================================================================\n",
    "#Block classification\n",
    "if not os.path.exists(dir_data): sys.exit('\\nError - Required folder: ' + dir_data + ' does not exist.')\n",
    "if not os.path.exists(dir_blocks_data) and (classifierBlocks or classifierExport): sys.exit('\\nError - Required folder: ' + dir_blocks_data + ' does not exist.')\n",
    "if not os.path.exists(dir_blocks_inputs) and (classifierBlocks or classifierExport): sys.exit('\\nError - Required folder: ' + dir_blocks_inputs + ' does not exist.')\n",
    "\n",
    "#WSI classification and RANDS\n",
    "if not os.path.exists(dir_WSI_data) and classifierWSI: sys.exit('\\nError - Required folder: ' + dir_WSI_data + ' does not exist.')\n",
    "if not os.path.exists(dir_WSI_inputs) and classifierWSI: sys.exit('\\nError - Required folder: ' + dir_WSI_inputs + ' does not exist.')\n",
    "#=============================================================================\n",
    "\n",
    "#If for a given task, file overwrites are not enabled, and the needed files do not exist, then enable the relevant overwrite(s)\n",
    "#If tasks are not to be performed, then disable overwrites to prevent folder/file removal\n",
    "#=============================================================================\n",
    "if classifierBlocks or classifierExport:\n",
    "    if not overwriteBlocks_features and len(glob.glob(dir_blocks_features+'*.npy'))==0: overwriteBlocks_features = True\n",
    "else:\n",
    "    overwriteBlocks_features = False\n",
    "    \n",
    "if classifierBlocks:\n",
    "    if not overwriteBlocks_saliencyMaps and len(glob.glob(dir_blocks_salicencyMaps+'*.npy'))==0: overwriteBlocks_saliencyMaps = True\n",
    "else:\n",
    "    overwriteBlocks_saliencyMaps = False\n",
    "    \n",
    "if classifierWSI:\n",
    "    if not overwriteWSI_blocks and len(glob.glob(dir_WSI_blocks+'*.npy'))==0: overwriteWSI_blocks = True\n",
    "    if not overwriteWSI_features and len(glob.glob(dir_WSI_features+'*.npy'))==0: overwriteWSI_features = True\n",
    "    if not overwriteWSI_saliencyMaps and len(glob.glob(dir_WSI_saliencyMaps+'*.npy'))==0: overwriteWSI_saliencyMaps = True\n",
    "else:\n",
    "    overwriteWSI_blocks = False\n",
    "    overwriteWSI_features = False\n",
    "    overwriteWSI_saliencyMaps = False\n",
    "    \n",
    "#=============================================================================\n",
    "\n",
    "\n",
    "#Regenerate empty files/folders that are to be overwritten\n",
    "#=============================================================================\n",
    "#Globabl\n",
    "if os.path.exists(dir_results): shutil.rmtree(dir_results)\n",
    "os.makedirs(dir_results)\n",
    "os.makedirs(dir_results_models)\n",
    "os.makedirs(dir_blocks_results)\n",
    "os.makedirs(dir_WSI_results)\n",
    "os.makedirs(dir_WSI_predictionMaps)\n",
    "\n",
    "#Block classification\n",
    "if overwriteBlocks_features and os.path.exists(dir_blocks_features): \n",
    "    shutil.rmtree(dir_blocks_features)\n",
    "    os.makedirs(dir_blocks_features)\n",
    "if overwriteBlocks_saliencyMaps and os.path.exists(dir_blocks_salicencyMaps): \n",
    "    shutil.rmtree(dir_blocks_salicencyMaps)\n",
    "    os.makedirs(dir_blocks_salicencyMaps)\n",
    "\n",
    "#WSI classification and RANDS\n",
    "if overwriteWSI_blocks: \n",
    "    if os.path.exists(dir_WSI_blocks): shutil.rmtree(dir_WSI_blocks)\n",
    "    os.makedirs(dir_WSI_blocks)\n",
    "    if os.path.exists(dir_WSI_prepared): shutil.rmtree(dir_WSI_prepared)\n",
    "    os.makedirs(dir_WSI_prepared)\n",
    "if overwriteWSI_features and os.path.exists(dir_WSI_features): \n",
    "    shutil.rmtree(dir_WSI_features)\n",
    "    os.makedirs(dir_WSI_features)\n",
    "if overwriteWSI_saliencyMaps: \n",
    "    if os.path.exists(dir_WSI_saliencyMaps): shutil.rmtree(dir_WSI_saliencyMaps)\n",
    "    os.makedirs(dir_WSI_saliencyMaps)\n",
    "    if os.path.exists(dir_WSI_assembled): shutil.rmtree(dir_WSI_assembled)\n",
    "    os.makedirs(dir_WSI_assembled)\n",
    "    if os.path.exists(dir_WSI_global): shutil.rmtree(dir_WSI_global)\n",
    "    os.makedirs(dir_WSI_global)\n",
    "\n",
    "#=============================================================================\n",
    "\n",
    "\n",
    "#If result folders do not exist, then create them\n",
    "#=============================================================================\n",
    "#Block classification\n",
    "if not os.path.exists(dir_blocks_features): os.makedirs(dir_blocks_features)\n",
    "if not os.path.exists(dir_blocks_salicencyMaps): os.makedirs(dir_blocks_salicencyMaps)\n",
    "\n",
    "#WSI classification and RANDS\n",
    "if not os.path.exists(dir_WSI_prepared): os.makedirs(dir_WSI_prepared)\n",
    "if not os.path.exists(dir_WSI_blocks): os.makedirs(dir_WSI_blocks)\n",
    "if not os.path.exists(dir_WSI_features): os.makedirs(dir_WSI_features)\n",
    "if not os.path.exists(dir_WSI_saliencyMaps): os.makedirs(dir_WSI_saliencyMaps)\n",
    "if not os.path.exists(dir_WSI_assembled_saliencyMaps): os.makedirs(dir_WSI_assembled_saliencyMaps)\n",
    "if not os.path.exists(dir_WSI_assembled_overlaid): os.makedirs(dir_WSI_assembled_overlaid)\n",
    "if not os.path.exists(dir_WSI_global_saliencyMaps): os.makedirs(dir_WSI_global_saliencyMaps)\n",
    "if not os.path.exists(dir_WSI_global_overlaid): os.makedirs(dir_WSI_global_overlaid)\n",
    "#=============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4586e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca3b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify image files\n",
    "class Classifier():\n",
    "    \n",
    "    #Load blocks specified by provided filenames, extract relevant features, and setup additional model components needed for training/evaluation\n",
    "    def __init__(self, blockFilenames, blockNamesAll, blockSampleNamesAll, sampleNamesAll, blockLabelsAll=None):\n",
    "        \n",
    "        #Store input variables internally\n",
    "        self.blockFilenames = blockFilenames\n",
    "        self.blockNamesAll = blockNamesAll\n",
    "        self.blockSampleNamesAll = blockSampleNamesAll\n",
    "        self.sampleNamesAll = sampleNamesAll\n",
    "        self.blockLabelsAll = blockLabelsAll\n",
    "        \n",
    "        #Prepare data objects for obtaining/processing PyTorch model inputs\n",
    "        self.device = f\"cuda:{gpus[-1]}\" if len(gpus) > 0 else \"cpu\"\n",
    "        self.torchDevice = torch.device(self.device)\n",
    "        self.blockData = DataPreprocessing_Classifier(blockFilenames)\n",
    "        self.blockDataloader = DataLoader(self.blockData, batch_size=batchsizeClassifier, num_workers=numberCPUS, shuffle=False, pin_memory=True)\n",
    "        self.numBlockData = len(self.blockDataloader)\n",
    "        self.blockWeights = []\n",
    "        \n",
    "    def computeFeatures(self, dir_features, overwrite_Features):\n",
    "        \n",
    "        #Extract or load features for the indicated block files\n",
    "        if overwrite_Features: \n",
    "        \n",
    "            #Load pretrained ResNet50 model and set to evaluation mode\n",
    "            model_ResNet = models.resnet50(weights=weightsResNet).to(self.torchDevice)\n",
    "            _ = model_ResNet.train(False)\n",
    "\n",
    "            #Extract features for each batch of sample block images\n",
    "            self.blockFeaturesAll = []\n",
    "            for data in tqdm(self.blockDataloader, total=self.numBlockData, desc='Feature Extraction', leave=True, ascii=asciiFlag):\n",
    "                self.blockFeaturesAll += model_ResNet(data.to(self.torchDevice)).detach().cpu().tolist()\n",
    "            \n",
    "            #Clear the ResNet model\n",
    "            del model_ResNet\n",
    "            if len(gpus) > 0: torch.cuda.empty_cache() \n",
    "            \n",
    "            #Convert list of features to an array\n",
    "            self.blockFeaturesAll = np.asarray(self.blockFeaturesAll)\n",
    "            \n",
    "            #Save features to disk\n",
    "            np.save(dir_features + 'blockFeaturesAll', self.blockFeaturesAll)\n",
    "            \n",
    "        else: \n",
    "            self.blockFeaturesAll = np.load(dir_features + 'blockFeaturesAll.npy', allow_pickle=True)\n",
    "        \n",
    "    def computeSalicencyMaps(self, dir_salicencyMaps, overwrite_saliencyMaps, visualize_saliencyMaps, visualize_saliencyMaps_WSI=False):\n",
    "        \n",
    "        #Extract or load saliency map data for the indicated block files\n",
    "        if overwrite_saliencyMaps:\n",
    "\n",
    "            #Load pre-trained DenseNet\n",
    "            model_DenseNet = models.densenet169(weights=weightsDenseNet)\n",
    "\n",
    "            #Replace the in-built classifier; unclear how this structure and these hyperparameters were determined\n",
    "            model_DenseNet.classifier = nn.Sequential(\n",
    "                nn.Linear(model_DenseNet.classifier.in_features, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.4),\n",
    "                nn.Linear(256, 2),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "            )\n",
    "            model_DenseNet = model_DenseNet.to(self.torchDevice)\n",
    "            _ = model_DenseNet.train(False)\n",
    "\n",
    "            #Create GradCAMPlusPlus model; see https://github.com/jacobgil/pytorch-grad-cam for additional models and options\n",
    "            model_GradCamPlusPlus = GradCAMPlusPlus(model=model_DenseNet, target_layers=[model_DenseNet.features[-1]])\n",
    "\n",
    "            #For each of the blocks generate and/or store directory locations to save visualizations\n",
    "            if visualize_saliencyMaps:\n",
    "                dir_salicencyMapAll = []\n",
    "                for sampleName in self.blockSampleNamesAll: \n",
    "                    \n",
    "                    #Create base sample directory\n",
    "                    dir_salicencyMap = dir_salicencyMaps + 'S' + sampleName + os.path.sep\n",
    "                    if not os.path.exists(dir_salicencyMap): os.makedirs(dir_salicencyMap)\n",
    "                    \n",
    "                    #Create sub-directory for the saliency maps\n",
    "                    dir_salicencyMap = dir_salicencyMap + 'SALIENCY_MAPS' + os.path.sep\n",
    "                    if not os.path.exists(dir_salicencyMap): os.makedirs(dir_salicencyMap)\n",
    "                    dir_salicencyMapAll.append(dir_salicencyMap)\n",
    "            \n",
    "            #Compute confidence weights for each block\n",
    "            self.blockWeightsAll = []\n",
    "            if visualize_saliencyMaps: self.filename_saliencyMapAll = []\n",
    "            for batchNum, data in tqdm(enumerate(self.blockDataloader), total=self.numBlockData, desc='Weight Computation', leave=True, ascii=asciiFlag):\n",
    "                \n",
    "                #Generate saliency maps for each block\n",
    "                blockSaliencyMaps = model_GradCamPlusPlus(input_tensor=data, targets=None)\n",
    "                \n",
    "                #For current GradCamPlusPlus implementation, must manually clear internal copy of the outputs from GPU cache to prevent OOM\n",
    "                del model_GradCamPlusPlus.outputs \n",
    "                if len(gpus) > 0: torch.cuda.empty_cache()\n",
    "                \n",
    "                #Compute regional importance for each block as the average saliency map values\n",
    "                blockImportances = np.mean(blockSaliencyMaps, axis=(1,2))\n",
    "                \n",
    "                #Threshold regional importance values by 0.25 to get block weights\n",
    "                self.blockWeightsAll += list(np.where(blockImportances<0.25, 0, blockImportances))\n",
    "                \n",
    "                #Perform visualization of block saliency maps; remove alpha channel when saving\n",
    "                if visualize_saliencyMaps:\n",
    "                    blockIndices = np.arange(batchNum*batchsizeClassifier, (batchNum+1)*batchsizeClassifier)\n",
    "                    for index in range(0, len(blockSaliencyMaps)):\n",
    "                        blockIndex = blockIndices[index]\n",
    "                        filename_saliencyMap = dir_salicencyMapAll[blockIndex] + 'saliencyMap_' + self.blockNamesAll[blockIndex] + '.tif'\n",
    "                        exportImage(filename_saliencyMap, matplotlib.cm.jet(blockSaliencyMaps[index])[:,:,:-1].astype(np.float32))\n",
    "                        self.filename_saliencyMapAll.append(filename_saliencyMap)\n",
    "                        \n",
    "            #Aggregate sample-specific visualizations into WSI, store per-block overlaid saliency maps, and compute a global saliency map similar to original work\n",
    "            if visualize_saliencyMaps_WSI: \n",
    "                for sampleName in tqdm(self.sampleNamesAll, desc='WSI Visualization', leave=True, ascii=asciiFlag):\n",
    "\n",
    "                    #Get block raw saliency map filenames specific to the sample\n",
    "                    blockIndices = np.where(self.blockSampleNamesAll == sampleName)[0]\n",
    "                    blockFilenames = np.asarray(self.filename_saliencyMapAll)[blockIndices]\n",
    "\n",
    "                    #Assuming the original order and image dimensions haven't been manipulated, the last filename will have the dimension data required\n",
    "                    numBlocksRow, numBlocksCol = np.asarray(os.path.basename(blockFilenames[-1]).split('.tif')[0].split('_')[-2:]).astype(int)+1\n",
    "                    blockStichSize = cv2.cvtColor(cv2.imread(blockFilenames[-1], cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB).shape\n",
    "\n",
    "                    #Load per-block saliency maps, reshape to original dimensions, and store to disk\n",
    "                    overlay = np.empty((numBlocksRow, numBlocksCol, blockStichSize[0], blockStichSize[1], blockStichSize[2]), dtype=np.float32)\n",
    "                    for filename in blockFilenames:\n",
    "                        rowNum, colNum = np.asarray(os.path.basename(filename).split('.tif')[0].split('_')[-2:]).astype(int)\n",
    "                        overlay[rowNum, colNum] = cv2.cvtColor(cv2.imread(filename, cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB)\n",
    "                    overlay = overlay.swapaxes(1,2)\n",
    "                    overlay = overlay.reshape(overlay.shape[0]*overlay.shape[1], overlay.shape[2]*overlay.shape[3], overlay.shape[4])\n",
    "                    exportImage(dir_WSI_assembled_saliencyMaps+'saliencyMap_'+sampleName+'.tif', overlay)\n",
    "\n",
    "                    #Load the processed sample image\n",
    "                    imageWSI = cv2.cvtColor(cv2.imread(dir_WSI_prepared + 'S' + sampleName + '.tif', cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    #Resize/rescale the WSI to match the overlay (staying consistent with existing data processing), then save it to disk\n",
    "                    transform = generateTransform(overlay.shape[:2], True, False)\n",
    "                    overlaid = np.moveaxis(transform(np.moveaxis(imageWSI, -1, 0)).numpy(), 0, -1)\n",
    "                    if overlayGray: overlaid = np.expand_dims(cv2.cvtColor(overlaid, cv2.COLOR_RGB2GRAY), -1)\n",
    "                    overlaid = show_cam_on_image(overlaid, overlay, use_rgb=True, colormap=cv2.COLORMAP_JET, image_weight=1.0-overlayWeight)\n",
    "                    exportImage(dir_WSI_assembled_overlaid+'overlaid_'+sampleName+'.tif', overlaid)\n",
    "\n",
    "                    #Split overlay back into blocks and flatten; doing this rather than saving per-block overlays provides global color consistency with the assembled result\n",
    "                    overlaid = overlaid.reshape(numBlocksRow, blockStichSize[0], numBlocksCol, blockStichSize[1], overlaid.shape[2]).swapaxes(1,2)\n",
    "                    overlaid = overlaid.reshape(-1, overlaid.shape[2], overlaid.shape[3], overlaid.shape[4])\n",
    "\n",
    "                    #Create sub-directory for overlaid saliency maps\n",
    "                    dir_salicencyMap_overlaid = dir_salicencyMaps + 'S' + sampleName + os.path.sep + 'OVERLAID' + os.path.sep\n",
    "                    os.makedirs(dir_salicencyMap_overlaid)\n",
    "                    \n",
    "                    #Store per-block overlaid saliency maps to disk\n",
    "                    for index in range(0, len(blockFilenames)): exportImage(dir_salicencyMap_overlaid + 'overlaid' + os.path.basename(blockFilenames[index]).split('saliencyMap')[1], overlaid[index])\n",
    "                    \n",
    "                    #Load the processed sample image\n",
    "                    imageWSI = cv2.cvtColor(cv2.imread(dir_WSI_prepared + 'S' + sampleName + '.tif', cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    #Resize/rescale/normalize the WSI, maintaining the original aspect ratio; \n",
    "                    resizeWSI = list(np.asarray(imageWSI.shape[:2])//(int(np.ceil(max(imageWSI.shape[:2])/maxDimGlobalSaliencyMap))))\n",
    "                    transform = generateTransform(resizeWSI, True, True)\n",
    "                    data = torch.unsqueeze(transform(np.moveaxis(imageWSI, -1, 0)), 0)\n",
    "                    \n",
    "                    #Compute the global saliency mask\n",
    "                    globalSaliencyMap = model_GradCamPlusPlus(input_tensor=data, targets=None)[0]\n",
    "                    \n",
    "                    #For current GradCamPlusPlus implementation, must manually clear internal copy of the outputs from GPU cache to prevent OOM\n",
    "                    del model_GradCamPlusPlus.outputs \n",
    "                    if len(gpus) > 0: torch.cuda.empty_cache()\n",
    "                    \n",
    "                    #If configured to resize the global saliency mask before export\n",
    "                    if globalSaliencyMaskResizeExport: \n",
    "                        transform = generateTransform(imageWSI.shape[:2], False, False)\n",
    "                        globalSaliencyMap = transform(np.expand_dims(globalSaliencyMap, 0))[0].numpy()\n",
    "                    \n",
    "                    #Store the global saliency mask to disk\n",
    "                    exportImage(dir_WSI_global_saliencyMaps+'global_saliencyMap_'+sampleName+'.tif', matplotlib.cm.jet(globalSaliencyMap)[:,:,:-1].astype(np.float32))\n",
    "                    \n",
    "                    #If not configured to resize the global saliency mask before export, then do so here, before overlay\n",
    "                    if not globalSaliencyMaskResizeExport: \n",
    "                        transform = generateTransform(imageWSI.shape[:2], False, False)\n",
    "                        globalSaliencyMap = transform(np.expand_dims(globalSaliencyMap, 0))[0].numpy()\n",
    "                    \n",
    "                    #Overlay the global saliency map back onto the WSI and save it to disk\n",
    "                    transform = generateTransform([], True, False)\n",
    "                    if overlayGray: overlaid = np.expand_dims(cv2.cvtColor(transform(imageWSI).numpy(), cv2.COLOR_RGB2GRAY), -1)\n",
    "                    overlaid = show_cam_on_image(overlaid, globalSaliencyMap, use_rgb=True, colormap=cv2.COLORMAP_JET, image_weight=1.0-overlayWeight)\n",
    "                    exportImage(dir_WSI_global_overlaid+'global_overlaid_'+sampleName+'.tif', overlaid)\n",
    "                    \n",
    "            #Clear the DenseNet and GradCamPlusPlus \n",
    "            del model_DenseNet, model_GradCamPlusPlus\n",
    "            if len(gpus) > 0: torch.cuda.empty_cache()\n",
    "            \n",
    "            #Convert list of new predictions to an array\n",
    "            self.blockWeightsAll = np.asarray(self.blockWeightsAll)\n",
    "            \n",
    "            #Save weights  to disk\n",
    "            np.save(dir_salicencyMaps + 'blockWeightsAll', self.blockWeightsAll)\n",
    "            \n",
    "        else:\n",
    "            self.blockWeightsAll = np.load(dir_salicencyMaps + 'blockWeightsAll.npy', allow_pickle=True)\n",
    "        \n",
    "    #Train a new XGB Classifier model\n",
    "    def train(self, inputs, labels):\n",
    "        self.model_XGBClassifier = XGBClassifier(device=self.device)\n",
    "        _  = self.model_XGBClassifier.fit(inputs.astype(np.float32), labels)\n",
    "        \n",
    "    #Classify extracted block features\n",
    "    def predict(self, inputs, fusionMode, weights=None):\n",
    "        \n",
    "        #Compute the raw block predictions\n",
    "        blockPredictions = self.model_XGBClassifier.predict(inputs.astype(np.float32))\n",
    "        \n",
    "        #If fusion mode is active, multiply the block predictions (using -1 for benign and +1 for malignant) by the matching weights; positive results are malignant\n",
    "        if fusionMode: \n",
    "            blockPredictionsFusion = np.where(blockPredictions==0, -1, 1)*weights\n",
    "            blockPredictionsFusion = np.where(blockPredictionsFusion>0, 1, 0)\n",
    "            return blockPredictions.tolist(), blockPredictionsFusion.tolist()\n",
    "        else: \n",
    "            return blockPredictions.tolist()\n",
    "        \n",
    "    #Perform cross-validation\n",
    "    def crossValidation(self):\n",
    "        \n",
    "        #If block weights are available, then enable evauation of fusion mode\n",
    "        if len(self.blockWeightsAll)>0: fusionMode = True\n",
    "        else: fusionMode = False\n",
    "        \n",
    "        #Allocate samples to folds for cross validation\n",
    "        if type(manualFolds) != list: folds = [array.tolist() for array in np.array_split(np.random.permutation(self.sampleNamesAll), manualFolds)]\n",
    "        else: folds = manualFolds\n",
    "        numFolds = len(folds)\n",
    "\n",
    "        #Split block features into specified folds, keeping track of originating indices and matched labels\n",
    "        foldsIndices, foldsFeatures, foldsLabels, foldsWeights, foldsSampleNames, foldsBlockNames = [], [], [], [], [], []\n",
    "        for fold in folds:\n",
    "            blockIndices = np.concatenate([np.where(self.blockSampleNamesAll == sampleName)[0] for sampleName in fold])\n",
    "            foldsIndices.append(blockIndices)\n",
    "            foldsFeatures.append(list(self.blockFeaturesAll[blockIndices]))\n",
    "            foldsLabels.append(list(self.blockLabelsAll[blockIndices]))\n",
    "            if fusionMode: foldsWeights.append(list(self.blockWeightsAll[blockIndices]))\n",
    "            foldsSampleNames.append(list(self.blockSampleNamesAll[blockIndices]))\n",
    "            foldsBlockNames.append(list(self.blockNamesAll[blockIndices]))\n",
    "\n",
    "        #Collapse indices, labels, and sample names for later (correct/matched ordered) evaluation of the fold data\n",
    "        blockIndices = np.concatenate(foldsIndices)\n",
    "        blockLabels = np.concatenate(foldsLabels)\n",
    "        blockSampleNames = np.concatenate(foldsSampleNames)\n",
    "        blockNames = np.concatenate(foldsBlockNames)\n",
    "\n",
    "        #Check class distribution between the folds\n",
    "        #print('B\\t M \\t Total')\n",
    "        #for foldNum in range(0, numFolds):\n",
    "        #    print(np.sum(np.array(foldsLabels[foldNum]) == 0),'\\t', np.sum(np.array(foldsLabels[foldNum]) == 1), '\\t', len(foldsLabels[foldNum]))\n",
    "\n",
    "        #Perform training/testing among the folds, storing test results for later evaluation\n",
    "        blockPredictions, blockPredictionsFusion = [], []\n",
    "        for foldNum in tqdm(range(0, numFolds), desc='Block Classification', leave=True, ascii=asciiFlag):\n",
    "            \n",
    "            #Train on all folds except the one specified\n",
    "            self.train(np.concatenate(foldsFeatures[:foldNum]+foldsFeatures[foldNum+1:]), np.concatenate(foldsLabels[:foldNum]+foldsLabels[foldNum+1:]))\n",
    "            \n",
    "            #Classify blocks in the specified, remaining fold\n",
    "            if fusionMode: \n",
    "                foldPredictions, foldPredictionsFusion = self.predict(np.asarray(foldsFeatures[foldNum]), fusionMode, np.asarray(foldsWeights[foldNum]))\n",
    "                blockPredictionsFusion += foldPredictionsFusion\n",
    "            else:\n",
    "                foldPredictions = self.predict(np.asarray(foldsFeatures[foldNum]), fusionMode)\n",
    "            blockPredictions += foldPredictions\n",
    "            \n",
    "            #Clear the XGBClassifier model\n",
    "            del self.model_XGBClassifier\n",
    "            if len(gpus) > 0: torch.cuda.empty_cache() \n",
    "            \n",
    "        #Convert lists of predictions to arrays\n",
    "        blockPredictions = np.asarray(blockPredictions)\n",
    "        blockPredictionsFusion = np.asarray(blockPredictionsFusion)\n",
    "        \n",
    "        #Sort data into natural order before output\n",
    "        indexOrder = natsort.index_natsorted(blockNames)\n",
    "        blockNames = blockNames[indexOrder]\n",
    "        blockSampleNames = blockSampleNames[indexOrder]\n",
    "        blockLabels = blockLabels[indexOrder]\n",
    "        blockPredictions = blockPredictions[indexOrder]\n",
    "        if fusionMode: blockPredictionsFusion = blockPredictionsFusion[indexOrder]\n",
    "        \n",
    "        #Save results to disk\n",
    "        dataPrintout, dataPrintoutNames = [blockNames, blockLabels, blockPredictions], ['Names', 'Labels', 'Raw Predictions']\n",
    "        if fusionMode: \n",
    "            dataPrintout.append(blockPredictionsFusion)\n",
    "            dataPrintoutNames.append('Fusion Predictions')\n",
    "        dataPrintout = pd.DataFrame(dataPrintout).transpose()\n",
    "        dataPrintout.columns=dataPrintoutNames\n",
    "        dataPrintout.to_csv(dir_blocks_results + 'predictions_blocks.csv', index=False)\n",
    "        \n",
    "        #Evaluate per-block results\n",
    "        computeClassificationMetrics(blockLabels, blockPredictions, dir_blocks_results+'results_Blocks_Initial')\n",
    "        if fusionMode: computeClassificationMetrics(blockLabels, blockPredictionsFusion, dir_blocks_results+'results_Blocks_Fusion')\n",
    "    \n",
    "        #Merge per-block results to obtain results for each WSI\n",
    "        sampleNames = np.unique(blockSampleNames)\n",
    "        sampleLabels, samplePredictions, samplePredictionsFusion = [], [], []\n",
    "        for sampleName in sampleNames:\n",
    "\n",
    "            #Find indices of samplename in sampleNames\n",
    "            sampleIndices = np.where(blockSampleNames == sampleName)[0]\n",
    "\n",
    "            #Determine if the number of malignant block predictions exceeds the configured threshold\n",
    "            sampleLabels.append((np.mean(blockLabels[sampleIndices]) >= thresholdWSI)*1)\n",
    "            samplePredictions.append((np.mean(blockPredictions[sampleIndices]) >= thresholdWSI)*1)\n",
    "            if fusionMode: samplePredictionsFusion.append((np.mean(blockPredictionsFusion[sampleIndices]) >= thresholdWSI)*1)\n",
    "\n",
    "        #Convert list of WSI labels/predictions to arrays\n",
    "        sampleLabels = np.asarray(sampleLabels)\n",
    "        samplePredictions = np.asarray(samplePredictions)\n",
    "        samplePredictionsFusion = np.asarray(samplePredictionsFusion)\n",
    "        \n",
    "        #Sort data into natural order before output\n",
    "        indexOrder = natsort.index_natsorted(sampleNames)\n",
    "        sampleNames = sampleNames[indexOrder]\n",
    "        sampleLabels = sampleLabels[indexOrder]\n",
    "        samplePredictions = samplePredictions[indexOrder]\n",
    "        if fusionMode: samplePredictionsFusion = samplePredictionsFusion[indexOrder]\n",
    "\n",
    "        #Save results to disk\n",
    "        dataPrintout, dataPrintoutNames = [sampleNames, sampleLabels, samplePredictions], ['Names', 'Labels', 'Raw Predictions']\n",
    "        if fusionMode: \n",
    "            dataPrintout.append(samplePredictionsFusion)\n",
    "            dataPrintoutNames.append('Fusion Predictions')\n",
    "        dataPrintout = pd.DataFrame(dataPrintout).transpose()\n",
    "        dataPrintout.columns=dataPrintoutNames\n",
    "        dataPrintout.to_csv(dir_blocks_results + 'predictions_WSI.csv', index=False)\n",
    "        \n",
    "        #Evaluate original WSI results\n",
    "        computeClassificationMetrics(sampleLabels, samplePredictions, dir_blocks_results+'results_WSI_Initial')\n",
    "        if fusionMode: computeClassificationMetrics(sampleLabels, samplePredictionsFusion, dir_blocks_results+'results_WSI_Fusion')\n",
    "\n",
    "    #Train on all available data and export models\n",
    "    def exportClassifier(self):\n",
    "        \n",
    "        #Setup, train, save, and clear the XGBClassifier model\n",
    "        self.train(self.blockFeaturesAll, self.blockLabelsAll)\n",
    "        \n",
    "        #Register converter for XGBClassifier\n",
    "        update_registered_converter(XGBClassifier, \"XGBoostXGBClassifier\", calculate_linear_classifier_output_shapes, convert_xgboost, options={\"nocl\": [True, False], \"zipmap\": [True, False, \"columns\"]},)\n",
    "        \n",
    "        #Convert classifier to onnx format and save to disk\n",
    "        model_onnx_XGBClassifier = to_onnx(modelClassifier_blocks.model_XGBClassifier, modelClassifier_blocks.blockFeaturesAll.astype(np.float32), target_opset={\"\": skl2onnx.__max_supported_opset__, \"ai.onnx.ml\": 3})\n",
    "        with open(dir_results_models + 'model_XGBClassifier.onnx', 'wb') as f:f.write(model_onnx_XGBClassifier.SerializeToString())\n",
    "        \n",
    "        del self.model_XGBClassifier\n",
    "        if len(gpus) > 0: torch.cuda.empty_cache() \n",
    "        \n",
    "    #Load a pretrained model\n",
    "    def loadClassifier(self):\n",
    "        self.model_XGBClassifier = onnxruntime.InferenceSession(dir_results_models + 'model_XGBClassifier.onnx', providers = [('CUDAExecutionProvider', {\"device_id\": gpus[-1]}), 'CPUExecutionProvider'])\n",
    "        self.model_XGBClassifier.predict = lambda inputs: session.run(None, {'X': inputs})[0]\n",
    "    \n",
    "    #Classify a sample WSI\n",
    "    #def classifyWSI(self, inputs):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aece8960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WSI Block Extraction: 100%|████████████████████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Feature Extraction: 100%|████████████████████████| 14/14 [00:02<00:00,  6.30it/s]\n",
      "Weight Computation: 100%|████████████████████████| 14/14 [00:08<00:00,  1.71it/s]\n",
      "WSI Visualization: 100%|███████████████████████████| 1/1 [00:06<00:00,  6.62s/it]\n"
     ]
    }
   ],
   "source": [
    "#==================================================================\n",
    "#DATA_PROCESSING\n",
    "#==================================================================\n",
    "\n",
    "#Define generalize labels used in place of the original, specific tissue labels\n",
    "benignLabel, malignantLabel, excludeLabel = 0, 1, 2\n",
    "\n",
    "#If configured for block classification and/or model export\n",
    "if classifierBlocks or classifierExport: \n",
    "    \n",
    "    #Load and process metadata for available blocks\n",
    "    blockNamesAll_blocks, blockLabelsAll_blocks = loadMetadata(file_blocks_labels)\n",
    "    blockSampleNamesAll_blocks = np.array([re.split('PS|_', blockName)[1] for blockName in blockNamesAll_blocks])\n",
    "    blockFilenamesAll_blocks = [dir_blocks_inputs + 'S' + blockSampleNamesAll_blocks[blockIndex] + os.path.sep + blockNamesAll_blocks[blockIndex] + '.tif' for blockIndex in range(0, len(blockNamesAll_blocks))]\n",
    "\n",
    "    #Prepare classifier\n",
    "    modelClassifier_blocks = Classifier(blockFilenamesAll_blocks, blockNamesAll_blocks, blockSampleNamesAll_blocks, np.unique(blockSampleNamesAll_blocks), blockLabelsAll_blocks)\n",
    "\n",
    "    #Compute block features\n",
    "    modelClassifier_blocks.computeFeatures(dir_blocks_features, overwriteBlocks_features)\n",
    "\n",
    "    #Compute saliency maps for the blocks\n",
    "    if fusionModeBlocks: modelClassifier_blocks.computeSalicencyMaps(dir_blocks_salicencyMaps, overwriteBlocks_saliencyMaps, visualizeBlocks_saliencyMaps)\n",
    "    \n",
    "    #Perform cross-validation\n",
    "    if classifierBlocks: modelClassifier_blocks.crossValidation()\n",
    "    \n",
    "    #Export classifier components\n",
    "    if classifierExport: modelClassifier_blocks.exportClassifier()\n",
    "\n",
    "#If configured for WSI classification and RANDS data generation\n",
    "if classifierWSI:\n",
    "\n",
    "    #Load and process metadata for available samples\n",
    "    sampleNamesAll_WSI, sampleLabelsAll_WSI = loadMetadata(file_WSI_labels)\n",
    "    sampleFilenamesAll = [dir_WSI_inputs + sampleNamesAll_WSI[sampleIndex] + '.jpg' for sampleIndex in range(0, len(sampleNamesAll_WSI))]\n",
    "    \n",
    "    #Either split WSI into or load filenames for previously generated blocks \n",
    "    #Original work resized WSI before splitting into blocks, which potentially introduced inconsistent artifacting from altering the native aspect ratio\n",
    "    if overwriteWSI_blocks:\n",
    "\n",
    "        #Extract uniform, non-overlapping blocks from each WSI; could probably parallelize this if given time to do so\n",
    "        blockNamesAll_WSI, blockSampleNamesAll_WSI, blockFilenamesAll_WSI = [], [], []\n",
    "        for filename in tqdm(sampleFilenamesAll, desc='WSI Block Extraction', leave=True, ascii=asciiFlag):\n",
    "\n",
    "            #Extract base sample name\n",
    "            sampleName = os.path.basename(filename).split('.jpg')[0]\n",
    "\n",
    "            #Load WSI image\n",
    "            imageWSI = cv2.cvtColor(cv2.imread(filename, cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            #Equalize image brightness with historgram equalization in YUV space and extract foreground with Otsu; no improvement, leaving for reference\n",
    "            #y, cr, cb = cv2.split(cv2.cvtColor(imageWSI, cv2.COLOR_RGB2YCrCb))\n",
    "            #imageWSI = cv2.cvtColor(cv2.merge((cv2.equalizeHist(y), cr, cb)), cv2.COLOR_YCR_CB2RGB)\n",
    "            #mask = cv2.threshold(cv2.cvtColor(imageWSI, cv2.COLOR_RGB2GRAY),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "            \n",
    "            #Crop image to the largest foreground area\n",
    "            mask = cv2.threshold(cv2.cvtColor(imageWSI, cv2.COLOR_RGB2GRAY),0,255,cv2.THRESH_BINARY)[1]\n",
    "            contour = max(cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0], key=cv2.contourArea)\n",
    "            x, y, w, h = cv2.boundingRect(contour) \n",
    "            imageWSI = copy.deepcopy(imageWSI)[y:y+h, x:x+w]\n",
    "\n",
    "            #Pad the image as needed (as symmetrially as possible) for an even division by the specified block size; compute numBlocks per row/column\n",
    "            padHeight = (int(np.ceil(imageWSI.shape[0]/blockSize))*blockSize)-imageWSI.shape[0]\n",
    "            padWidth = (int(np.ceil(imageWSI.shape[1]/blockSize))*blockSize)-imageWSI.shape[1]\n",
    "            padTop, padLeft = padHeight//2, padWidth//2\n",
    "            padBottom, padRight = padTop+(padHeight%2), padLeft+(padWidth%2)\n",
    "            imageWSI = np.pad(imageWSI, ((padTop, padBottom), (padLeft, padRight), (0, 0)))\n",
    "            numBlocksRow, numBlocksCol = imageWSI.shape[0]//blockSize, imageWSI.shape[1]//blockSize\n",
    "\n",
    "            #Save processed WSI for ease of later visualization\n",
    "            exportImage(dir_WSI_prepared + 'S' + sampleName + '.tif', imageWSI)\n",
    "\n",
    "            #Split the WSI into blocks and flatten\n",
    "            imageWSI = imageWSI.reshape(numBlocksRow, blockSize, numBlocksCol, blockSize, imageWSI.shape[2]).swapaxes(1,2)\n",
    "            imageWSI = imageWSI.reshape(-1, imageWSI.shape[2], imageWSI.shape[3], imageWSI.shape[4])\n",
    "\n",
    "            #Setup directory to store blocks\n",
    "            dir_WSI_sample_blocks = dir_WSI_blocks + 'S' + sampleName + os.path.sep\n",
    "            if not os.path.exists(dir_WSI_sample_blocks): os.makedirs(dir_WSI_sample_blocks)\n",
    "            \n",
    "            #Generate names and filenames for each block \n",
    "            blockNames_WSI, blockSampleNames_WSI, blockFilenames_WSI = [], [], []\n",
    "            for rowNum in range(0, numBlocksRow):\n",
    "                for colNum in range(0, numBlocksCol):\n",
    "                    blockName = sampleName+'_'+str(rowNum)+'_'+str(colNum)\n",
    "                    blockNames_WSI.append(blockName)\n",
    "                    blockSampleNames_WSI.append(sampleName)\n",
    "                    blockFilenames_WSI.append(dir_WSI_sample_blocks+'PS'+blockName+'.tif')\n",
    "            \n",
    "            blockNamesAll_WSI += blockNames_WSI\n",
    "            blockSampleNamesAll_WSI += blockSampleNames_WSI\n",
    "            blockFilenamesAll_WSI += blockFilenames_WSI\n",
    "            \n",
    "            #Store blocks to disk\n",
    "            for index in range(0, len(blockFilenames_WSI)): exportImage(blockFilenames_WSI[index], imageWSI[index])\n",
    "        \n",
    "        #Clean the last WSI from RAM\n",
    "        del imageWSI\n",
    "        cleanup()\n",
    "        \n",
    "        #Save names and filenames to disk; relies on original filename ordering for re-assembling blocks during visualization\n",
    "        blockSampleNamesAll_WSI = np.asarray(blockSampleNamesAll_WSI)\n",
    "        blockFilenamesAll_WSI = np.asarray(blockFilenamesAll_WSI)\n",
    "        np.save(dir_WSI_blocks + 'blockNamesAll_WSI', blockNamesAll_WSI)\n",
    "        np.save(dir_WSI_blocks + 'blockSampleNamesAll_WSI', blockSampleNamesAll_WSI)\n",
    "        np.save(dir_WSI_blocks + 'blockFilenamesAll_WSI', blockFilenamesAll_WSI)\n",
    "        \n",
    "    else: \n",
    "        blockNamesAll_WSI = np.load(dir_WSI_blocks + 'blockNamesAll_WSI.npy', allow_pickle=True)\n",
    "        blockSampleNamesAll_WSI = np.load(dir_WSI_blocks + 'blockSampleNamesAll_WSI.npy', allow_pickle=True)\n",
    "        blockFilenamesAll_WSI = np.load(dir_WSI_blocks + 'blockFilenamesAll_WSI.npy', allow_pickle=True)\n",
    "\n",
    "    #Prepare classifier\n",
    "    modelClassifier_WSI = Classifier(blockFilenamesAll_WSI, blockNamesAll_WSI, blockSampleNamesAll_WSI, sampleNamesAll_WSI)\n",
    "    \n",
    "    #Compute block features\n",
    "    modelClassifier_WSI.computeFeatures(dir_WSI_features, overwriteWSI_features)\n",
    "\n",
    "    #Compute saliency maps for the blocks\n",
    "    if fusionModeWSI: modelClassifier_WSI.computeSalicencyMaps(dir_WSI_saliencyMaps, overwriteWSI_saliencyMaps, visualizeWSI_saliencyMaps, True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603dfb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Compute predictions for the blocks and WSI\n",
    "\n",
    "#Still need to export ResNet50 model to onnx as well (will be leaving DenseNet and GradCam to one side for now...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
